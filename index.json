[{"categories":["技术支持"],"content":" 本文于 2022年4月15日发表于有赞技术支持公众号 链接：https://mp.weixin.qq.com/s/tMAouzvBzyb-uCsVlMLdsA 在企业服务行业，了解客户的使用场景，倾听来自客户的使用反馈，分析客户的需求，并持续改善产品的使用体验，对产品的销售拓客、客户续费都有着积极的影响。 有一些中小规模的企业服务产品，产品运营团队可能承担了一部分客户的支持和答疑工作，也就是客户的吐槽、反馈能直接抵达产品研发团队，客户的有价值的需求就能快速加入到主线的研发流程中，进一步提升客户的产品使用体验。 但是事情并不是都如此理想化，在一些功能和技术密度更加复杂的企业服务产品中，售后技术支持的角色是不可或缺的。也就是售后技术支持的出现，让很大比例的客户问题在售后技术支持一侧进行了闭环，为产品和研发团队缓解了大量的日常咨询和答疑压力。 然而售后支持的出现也会带来另一个问题，也就是上面说的，客户和产品研发之间出现了一个售后团队，如何让产品研发团队能直观清晰的感知来自客户的重要的需求和吐槽，成了新的需要解决的难题。 在有赞，我们认为一个健康的技术支持，日常的工作精力绝对不能 100% 分布在解决商家的线上问题上。解决线上问题很重要，但是如果只解决线上问题，对团队和对个人都是一种慢性伤害。 因此，有赞技术支持除了解决线上问题，另一个典型的工作内容就是分析商家反馈的线上问题，从自己负责的产品模块中，分析出高频商家问题、可以优化的产品细节，以及评估 BUG 是否潜在升级为故障的风险，将这些内容快速的反馈到产研团队，并推进他们排期迭代。 敏锐的你一定发现上文 「推进他们排期迭代」是一个高度抽象和概括的描述，那么具体要怎么做才能让产研认可你提到优化点，是「迫切、批量、重要」的商家需求和线上问题，而不是一拍脑袋的「野需求」呢？没错，就像软件开发工程师圈子的那句话类似：「Talk is cheap ，show me the code」。在推进产研优化这块，同样「Talk is cheap」，此时我们就需要 「show you the results of data analysis」 为了能收集到数据，有赞技术支持在承接线上问题的工单系统中，分了这几个维度去标记每一个线上问题： 问题归属的产品模块 问题归属类型（有效咨询、技术 BUG、无效问题、产品 BUG） 问题归属的商家分级 每一个技术支持在处理线上问题的过程中，都会对这些问题进行打标分类，以便后续通过数据统计平台进行数据展示。 通过上述三个维度，我们就能分析出： 具体是哪一个产品模块出现的商家咨询量最多。 产品逻辑缺陷、或者技术 BUG 导致的问题有哪些。 重点客户的线上问题的具体情况。 最后在数据分析页面，我们就能方便的统计想要查看的线上问题的趋势、分类以及明细列表的视图。哪些产品模块，哪些重点客户、哪些 BUG问题需要重点优化，就非常的清晰明了。 示例界面： 实际上，有赞的产品细节非常的庞大，至今技术支持还需要通过查阅各类数据分析，去手动去生成一些线上问题双周报、月报等报表数据。我们仍然在致力于通过日常标准化的对每个问题打标的动作，然后自动生成线上问题数据报表。 一份完整的阶段售后支持报告，包含了这些内容： 售后支持统计，包括：数量趋势，各个流转环节的效率等。 软件质量分析，包括：BUG 分类，故障、以及故障预警，BUG 验收质量等。 需求进展分析，包括：商家需求、高频问题、技术干预等 这份全面的报表，可以按需自动生成多个部门的报表，触达各个产研部门。技术支持无需再去各个平台收集数据手动统计报表，统一生成的规范的报表，对技术支持来说也是一个生产力的解放。 我们常说互联网行业创业有很多的赛道，而选好赛道起跑后，大到公司运营，小到部门协作，都需要依赖各种分析数据进行决策，以确定下一步的重点和发展方向。 回到售后支持如何推进商家需求的话题上还是如此，对线上问题进行完善的分类标记，产出客观准确的数据，然后用数据去驱动产品的优化，是最准确、有效且让人信服的方式。 ","date":"2022-04-18","objectID":"/tech_support_wechat_article/:0:0","tags":["技术支持"],"title":"用数据分析驱动产品优化","uri":"/tech_support_wechat_article/"},{"categories":["python"],"content":"前段时间购买了@piglei 的《Python 工匠》，现在已经看了 1/3 了，这本书的行文的确是流畅，看起来很舒服，对于 Python 的高阶用法的建议和说明也都非常的不错，我打算开一篇博文单独记录一下，一些自己比较容易遗漏或者忘记的一些知识点。 ","date":"2022-04-05","objectID":"/python-books/:0:0","tags":["python","读书笔记"],"title":"03.关于《Python 工匠》的摘要笔记","uri":"/python-books/"},{"categories":["python"],"content":"近期在使用 SQLAlchemy 读取大批量数据的时候，遇到了一个问题，因为数据量过大而查询进程被 Kill 的问题，就想到了使用生成器或者单个请求拆分多次查询的方法。在 github 上找到了一篇 Wiki，照着 Wiki 中的方式，成功解决了 SQLAlchemy 查大数据失败的问题。 这篇 Wiki 文章比较短小，英文读起来也不吃力，但想着还是顺便练习一下翻译，水一篇博客好了。 ","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:0","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":["python"],"content":"译文： Todo ","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:1","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":["python"],"content":"原文： 原文链接：RangeQuery-and-WindowedRangeQuery： RangeQuery and WindowedRangeQuery The goal is to select through a very large number of rows that’s too large to fetch all at once. Many DBAPIs pre-buffer result sets fully, and otherwise it can be difficult to keep an active cursor when using an option like psycopg2’s server side cursors. The usual alternative, i.e. to page through the results using LIMIT/OFFSET, has the downside that the OFFSET will scan through all the previous rows each time in order to get to the requested row. To overcome this, there are two approaches to page through results without using OFFSET. The simplest is to order the results by a particular unique column (usually primary key), then fetch chunks using LIMIT only, adding a WHERE clause that will ensure we only fetch rows greater than the last one we fetched). This will work for basically any database backend and is illustrated below for MySQL. The potential downside is that the database needs to sort the full set of remaining rows for each chunk, which may inefficient, even though both recipes presented here assume the sort column is indexed. However, the approach is very simple and can likely work for most ordinary use cases for a primary key column on a database that does not support window functions. def windowed_query(q, column, windowsize): \"\"\"\"Break a Query into chunks on a given column.\"\"\" single_entity = q.is_single_entity q = q.add_column(column).order_by(column) last_id = None while True: subq = q if last_id is not None: subq = subq.filter(column \u003e last_id) chunk = subq.limit(windowsize).all() if not chunk: break last_id = chunk[-1][-1] for row in chunk: if single_entity: yield row[0] else: yield row[0:-1] if __name__ == \"__main__\": from sqlalchemy import Column, Integer, create_engine from sqlalchemy.orm import Session from sqlalchemy.ext.declarative import declarative_base import random Base = declarative_base() class Widget(Base): __tablename__ = \"widget\" id = Column(Integer, primary_key=True) data = Column(Integer) e = create_engine(\"mysql://scott:tiger@localhost/test\", echo=\"debug\") Base.metadata.drop_all(e) Base.metadata.create_all(e) # get some random list of unique values data = set([random.randint(1, 1000000) for i in range(10000)]) s = Session(e) s.add_all([Widget(id=i, data=j) for i, j in enumerate(data, 1)]) s.commit() q = s.query(Widget) for widget in windowed_query(q, Widget.data, 1000): print(\"data:\", widget.data) A more elaborate way to do this, which allows that the table rows are fully sorted only once, is to use a window function in order to establish the exact range for each “chunk” ahead of time, and then to yield chunks as rows selected within that range. This works only on databases that support windows functions. This recipe has been on the SQLAlchemy Wiki for a long time but it’s not clear how much advantage it has over the previous simpler approach; both approaches should be evaluated for efficiency for a given use case. import sqlalchemy from sqlalchemy import and_, func def column_windows(session, column, windowsize): \"\"\"Return a series of WHERE clauses against a given column that break it into windows. Result is an iterable of tuples, consisting of ((start, end), whereclause), where (start, end) are the ids. Requires a database that supports window functions, i.e. Postgresql, SQL Server, Oracle. Enhance this yourself ! Add a \"where\" argument so that windows of just a subset of rows can be computed. \"\"\" def int_for_range(start_id, end_id): if end_id: return and_( column\u003e=start_id, column\u003cend_id ) else: return column\u003e=start_id q = session.query( column, func.row_number().\\ over(order_by=column).\\ label('rownum') ).\\ from_self(column) if windowsize \u003e 1: q = q.filter(sqlalchemy.text(\"rownum %%%d=1\" % windowsize)) intervals = [id for id, in q] while intervals: start = intervals.pop(0) if intervals: end = intervals[0] else: end = None yield int_for_range(start, end) def windowed_query(q, column, windowsize): \"\"\"\"Break a Qu","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:2","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":null,"content":"做为混迹互联网行业十几年的中年人，曾经搭建好几次的博客以及微信公众号，但实际上并未保持持续写博客的状态，实际上在过往写过一部分文章，都零散的分散在电脑的各个角落里面。 如今再一次用 hugo 以及现成的 LoveIt 主题搭建了一个博客，那么，接下去除了写点新的东西以外，几篇老文章到时候也陆陆续续在这里露露面好了。 ","date":"2022-04-02","objectID":"/first_post/:0:0","tags":null,"title":"01.博客开篇","uri":"/first_post/"}]