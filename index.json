[{"categories":["技术支持"],"content":" 本文于 2023年1月31日发表于有赞技术支持公众号 链接：Todo 回想起来，2022年下半年有两大 AI 界的爆发性产品破圈进入大家视野，一个是 AI 画图（代表：Stable Diffusion），另一个是理解人类语言文本的 AI 会话（代表：ChatGPT ）。这两个 AI 产品的应用激起了业内外广泛的讨论，很多人都说设计师、插画师甚至可以转行成 AI 绘图输入条件的「场景描述师」了。可见这些工具给行业带来的改变和冲击是相当大的。 那么，涉及到问答场合下，能几乎和人类一样和用户进行沟通的 ChatGPT，以及它背后的语言模型训练的AI 技术，能给技术支持，或者说扩大一些范围，企业客户的售后服务领域下带来怎样的改变呢？ 至少，ChatGPT 是很有信心的： 在 ChatGPT 横空出世之前，其实能降低客服团队接线压力的智能问答机器人已经很普遍了。比如，我们在各类电商平台购物过程需要与商家进行沟通的时候，与我们进行第一道沟通的就是这些机器人助手，它们会首先将高频的问答直接展现在你面前，比如「有优惠活动吗」、「我的快递什么时候能到」。方便用户能直接点击相应的高频问题链接找到自己想要了解的问题的答案。 然而我们在和这些智能机器人沟通的时候，很多时候还会觉得这些「人工智能」还是有一点「人工智障」，会回复一些完全不相干的答复，或者直接就无法理解我们的问题。为此，我还特意去请教了一下 ChatGPT： 好家伙，缺点都被你说尽了。 实际上，智能机器人在近些年来的不断迭代，早已经比最初的通过关键词来定位答复的要优秀多了。但还是有一些技术难点没有攻克，在我看来，核心的内容主要是 ChatGPT 也提到的： 自然语言处理能力有限: 在自然语言处理方面缺乏能力, 无法正确理解客户询问, 导致回答不准确. 中文的博大精神，导致同样的一个意思可能有非常多的表达方式，或者相同的一句话，结合上下文会有多种意思。极端的例子：「我想我是时候和你再见了」这句话如果不根据上下文，就能两种截然相反的意思。或者我们想要知道自己什么时候能收到快递，问法也有很多种。这就对语言处理识别有极高的要求。 那么，为什么 ChatGPT 的出现，能给大家带来如此大的震撼呢？在我与它进行了多次深入浅出的对话后，整体总结出了以下几个其他智能会话机器人还不具备的能力： 强大的理解对话上下文的能力。 比如，在沟通过程中，如果与 ChatGPT 聊过买手机的话题，并且在后续的沟通中，用户输入了「我喜欢苹果」，此时 ChatGPT 是能够根据上下文推断出来，此时的「苹果」属于一个手机品牌，而并不是一个水果。 独树一帜的自然语言语义识别能力。 这个也是一大亮点，在与 ChatGPT 的沟通过程中，它已经能精确的识别到一些具备多重含义的语句了。 ChatGPT 在这两个方面做到了非常好的突破，使得人类和它沟通是一个很真实、且有意思的事情，让人机交谈的体验有了一个巨大的飞跃。 那么，既然 ChatGPT 体验这么好，并且 OpenAI 也提供了 GPT-3 Deploy API ，通过 API 接入到产品中提供售后的智能支持，会是一个重大的效率突破的点吗？ 我的答案是：不是，但这个「不是」并没有否定机器人智能会话，而是，ChatGPT 更像是一个 OpenAI 放出来的一个展现 AI 实力的一个 Demo，ChatGPT 有时候会用一本正经的语气提供出一个错误的答案，并且在很多非常专业的知识或者产品细节上仍然缺乏语料的训练，很难满足在这些方面提供解答和支持。 其背后真正有价值的是底层 AI 技术，然后将专业的产品知识和问题对其进行训练，通过人工审核和人工干预来检查模型输出，及时纠正错误，保证 「GPT」们能顺利识别用户的疑问，提供出正确的回复。这个才是售后支持核心的提效点。 相信，未来随着核心的自然语言语义识别能力技术的进一步普及和发展，会出现更多更好用的智能支持场景，大大提高客户的咨询体验，并且大大降低企业的成本。 在有赞技术支持，我们也非常认可 AI 是下一代用户体验的提升方向。我们已经在不断的探索智能支持方向上的应用。比如： 借助第四范式、以及飞书服务台机器人来自动根据关键词匹配一些知识库，更加方便和高效的匹配到正确的问题。 为有赞自研的 AI 服务训练工单的数据，匹配过往已经解决的工单，为新的工单提供解决方案上面的参考，可以快速缩短一些问题的排查时间。 最后，我们再让 ChatGPT 帮我们做件事情吧，也欢迎大家去 chat.openai.com 解锁更多的玩法。 ","date":"2023-01-28","objectID":"/wechat_chatgpt/:0:0","tags":["技术支持"],"title":"07.ChatGPT 是不是提升客户支持效率的银弹？","uri":"/wechat_chatgpt/"},{"categories":["生活"],"content":" 本文记录一下饭组的端午节千岛湖环湖自驾计划（也就是计划一下如何把大伙儿拐进山里面） ","date":"2022-05-30","objectID":"/a_way_to_home/:0:0","tags":["生活"],"title":"06.饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"需求 想要去自然风景好的, 人挤人的不太喜欢 – 雪姨 ","date":"2022-05-30","objectID":"/a_way_to_home/:0:1","tags":["生活"],"title":"06.饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"出发前准备 72 小时核酸检测做一下，确保旅游时间内，核酸都在有效期内。 自驾汽车状态检查一下，确保路途自驾安全，自驾来回预计消耗半箱油。 照相机📷，打卡必备。 手机充电线以及充电宝。 一套换洗衣物避免意外需要换洗的场景。 防蚊虫喷雾、防晒喷雾、酒精棉片，碘伏等简易应急物品 ","date":"2022-05-30","objectID":"/a_way_to_home/:0:2","tags":["生活"],"title":"06.饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"概览 时间：2022年6月3日 ～ 2022年6月4日 地点：杭州千岛湖环湖县道，姜家镇老家 人数：7大人，1小孩 交通：自驾汽车🚗 2 辆 住宿：乡下大别野 天气预报：6月3日和6月4日有雨🌧️，降水概率 80%、90%，记得带伞🌂，穿着不易湿的鞋👟 费用估算：todo 地图： ","date":"2022-05-30","objectID":"/a_way_to_home/:0:3","tags":["生活"],"title":"06.饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"详细行程 day01 从杭州出发，到千岛湖，出发时间：09:00，预期路上耗费时间：2小时30分，预期抵达千岛湖镇时间：11:30。 首站直接驱车到鱼街停车吃饭，鱼街有很多餐馆，各个餐馆的菜品都类似，所以差别不大，可以直接大众点评走起，或者看中哪个店面直接进去就行。 推荐：鱼、螺蛳等。 吃完饭可以在鱼街走一下，看一下鱼街的水池里面的鱼，有比人还长的中华鲟。 吃完午饭的后，继续沿着淳杨线 沿着湖南边的县道前进。淳杨线上能看到很多的湖景。而且，这是一条非常有名的骑行路线。 我们可以在沿湖碰到风景特别好的地方停车休息，欣赏一下绿水青山，有湖和山的地方，其实在雨后初晴，远处云雾弥漫的时候是最好看的。这种天气是可遇不可求的。 记录一下可以去的沿湖景点： 芹川古村落（免费）: 千岛湖北岸大山深处的一座750多年的古村落. 生态景区龙川湾门票（60/人）：龙川湾主要是一个自然风景+知青文化相关的景点，地方很大，理论上人很少。也有各类项目，包括钓鱼佬最爱的垂钓活动。具体的可以参考：哔哩哔哩的一个视频 文渊狮城（55/人）：这个地方就是一个类似河坊街的仿古小镇。大约重现了一下，被千岛湖水淹没的遂安县古镇的样子吧。 晚饭： 姜家镇上有比较多的农家餐厅，理论上人很少，继续大众点评一把梭就行。这里的选择就没有千岛湖镇上多了。 吃完晚饭后，可以在镇上采购一波零食，然后驱车往郭村方向出发，目的地是乡下大别野。 在进村的路上，还有一处景点，就是理学家朱熹曾经游学并且写下「问渠那得清如许，为有源头活水来」的诗句的瀛山书院遗址，对我来说，印象中就是一个山头上的一个亭子，就这么点印象了。 到了大别野安顿整理完床铺后，可以去田野压田埂，听听小溪边上的流水声，看一下头顶的星空，感受一下久违的寂静的乡村的感觉。 day02 todo 行程： 潘家村里面的深山爬山（入夏可能有有蛇虫，建议不入深山） 梅峰观岛 千岛湖大桥 ","date":"2022-05-30","objectID":"/a_way_to_home/:0:4","tags":["生活"],"title":"06.饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"老拱墅区：拱宸桥附近、拱北小区附近，以及后来混迹过的西湖区益乐新村、政苑小区都有特别多的回忆。如今已经到了无暇去回顾这些回忆的阶段了。 昨天带着小孩户外活动，但天气不好，下了点小雨，在古翠路公园绕了一圈就打算去原先常常走过的小街道逛逛。西湖区的世纪新城以及嘉绿苑周边的街道，都潜藏这很多的宝藏小店。各种有氛围和年代的大小咖啡店、还有十几年如一日，至今仍然不支持手机点餐的港式茶餐厅等等。 我原本想着一边走一边和幼崽讲述他老爹以前在这条路上吃过的东西，做过的事情。然而走了一段路后才发现，鲜有店面经过时间的洗礼还依旧存活至今。很多之前吃过饭的店面，到现在都已经不见了，取而代之的是另一个承载了其他人回忆的小店。尽管他们看起来也很「宝藏」，但不是我的宝藏小店了。 所以对不同的人来说，所谓的「宝藏」其实是相对的，物件身上承载的情怀第一，价值等其他属性次之。 路过一家蛋糕店，因为临近傍晚了，店里面几乎卖光了今日的蛋糕，但柜台里面还有一盒马卡龙小蛋糕，买了它尝了尝，结果太甜了，喜欢吃糖的儿子也这么说。 回来的路上经过了一家卖各种酒类的小店，我突然想起了8年前曾经在这家店里买过的酒，我们买了很多很多的进口啤酒，运回公司，放在一个装满冰块的汽油桶里面，开始开 party。我喝着酒，开着电脑给客户解答问题。那是一个无限可能的日子里。 这家卖酒的店还在，是这些街道上为数不多的还开着的店。傍晚的灯光亮起来，特别好看。我退后几步，照了张相 但是我已经回忆不起来当时买酒的时候，它是不是这家店，是不是换过名字了？是不是换过老板了，我一无所知。 天色渐渐暗下来，于是带着儿子跨上小红车回家去了，西湖区很多老破小，但是很生活的味道，是一种很老，却很有生命力的味道。 街拍照片已经上传至我的 IG ","date":"2022-04-25","objectID":"/westlake_district/:0:0","tags":["生活"],"title":"05.昨天遛了个街...","uri":"/westlake_district/"},{"categories":["技术支持"],"content":" 本文于 2022年4月15日发表于有赞技术支持公众号 链接：https://mp.weixin.qq.com/s/tMAouzvBzyb-uCsVlMLdsA 在企业服务行业，了解客户的使用场景，倾听来自客户的使用反馈，分析客户的需求，并持续改善产品的使用体验，对产品的销售拓客、客户续费都有着积极的影响。 有一些中小规模的企业服务产品，产品运营团队可能承担了一部分客户的支持和答疑工作，也就是客户的吐槽、反馈能直接抵达产品研发团队，客户的有价值的需求就能快速加入到主线的研发流程中，进一步提升客户的产品使用体验。 但是事情并不是都如此理想化，在一些功能和技术密度更加复杂的企业服务产品中，售后技术支持的角色是不可或缺的。也就是售后技术支持的出现，让很大比例的客户问题在售后技术支持一侧进行了闭环，为产品和研发团队缓解了大量的日常咨询和答疑压力。 然而售后支持的出现也会带来另一个问题，也就是上面说的，客户和产品研发之间出现了一个售后团队，如何让产品研发团队能直观清晰的感知来自客户的重要的需求和吐槽，成了新的需要解决的难题。 在有赞，我们认为一个健康的技术支持，日常的工作精力绝对不能 100% 分布在解决商家的线上问题上。解决线上问题很重要，但是如果只解决线上问题，对团队和对个人都是一种慢性伤害。 因此，有赞技术支持除了解决线上问题，另一个典型的工作内容就是分析商家反馈的线上问题，从自己负责的产品模块中，分析出高频商家问题、可以优化的产品细节，以及评估 BUG 是否潜在升级为故障的风险，将这些内容快速的反馈到产研团队，并推进他们排期迭代。 敏锐的你一定发现上文 「推进他们排期迭代」是一个高度抽象和概括的描述，那么具体要怎么做才能让产研认可你提到优化点，是「迫切、批量、重要」的商家需求和线上问题，而不是一拍脑袋的「野需求」呢？没错，就像软件开发工程师圈子的那句话类似：「Talk is cheap ，show me the code」。在推进产研优化这块，同样「Talk is cheap」，此时我们就需要 「show you the results of data analysis」 为了能收集到数据，有赞技术支持在承接线上问题的工单系统中，分了这几个维度去标记每一个线上问题： 问题归属的产品模块 问题归属类型（有效咨询、技术 BUG、无效问题、产品 BUG） 问题归属的商家分级 每一个技术支持在处理线上问题的过程中，都会对这些问题进行打标分类，以便后续通过数据统计平台进行数据展示。 通过上述三个维度，我们就能分析出： 具体是哪一个产品模块出现的商家咨询量最多。 产品逻辑缺陷、或者技术 BUG 导致的问题有哪些。 重点客户的线上问题的具体情况。 最后在数据分析页面，我们就能方便的统计想要查看的线上问题的趋势、分类以及明细列表的视图。哪些产品模块，哪些重点客户、哪些 BUG问题需要重点优化，就非常的清晰明了。 示例界面： 实际上，有赞的产品细节非常的庞大，至今技术支持还需要通过查阅各类数据分析，去手动去生成一些线上问题双周报、月报等报表数据。我们仍然在致力于通过日常标准化的对每个问题打标的动作，然后自动生成线上问题数据报表。 一份完整的阶段售后支持报告，包含了这些内容： 售后支持统计，包括：数量趋势，各个流转环节的效率等。 软件质量分析，包括：BUG 分类，故障、以及故障预警，BUG 验收质量等。 需求进展分析，包括：商家需求、高频问题、技术干预等 这份全面的报表，可以按需自动生成多个部门的报表，触达各个产研部门。技术支持无需再去各个平台收集数据手动统计报表，统一生成的规范的报表，对技术支持来说也是一个生产力的解放。 我们常说互联网行业创业有很多的赛道，而选好赛道起跑后，大到公司运营，小到部门协作，都需要依赖各种分析数据进行决策，以确定下一步的重点和发展方向。 回到售后支持如何推进商家需求的话题上还是如此，对线上问题进行完善的分类标记，产出客观准确的数据，然后用数据去驱动产品的优化，是最准确、有效且让人信服的方式。 ","date":"2022-04-18","objectID":"/tech_support_wechat_article/:0:0","tags":["技术支持"],"title":"04.用数据分析驱动产品优化","uri":"/tech_support_wechat_article/"},{"categories":["python"],"content":"前段时间购买了@piglei 的《Python 工匠》，现在已经看了 1/3 了，这本书的行文的确是流畅，看起来很舒服，对于 Python 的高阶用法的建议和说明也都非常的不错，我打算开一篇博文单独记录一下，一些自己比较容易遗漏或者忘记的一些知识点。 ","date":"2022-04-05","objectID":"/python-books/:0:0","tags":["python","读书笔记"],"title":"03.关于《Python 工匠》的摘要笔记","uri":"/python-books/"},{"categories":["python"],"content":"近期在使用 SQLAlchemy 读取大批量数据的时候，遇到了一个问题，因为数据量过大而查询进程被 Kill 的问题，就想到了使用生成器或者单个请求拆分多次查询的方法。在 github 上找到了一篇 Wiki，照着 Wiki 中的方式，成功解决了 SQLAlchemy 查大数据失败的问题。 这篇 Wiki 文章比较短小，英文读起来也不吃力，但想着还是顺便练习一下翻译，水一篇博客好了。 ","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:0","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":["python"],"content":"译文： Todo ","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:1","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":["python"],"content":"原文： 原文链接：RangeQuery-and-WindowedRangeQuery： RangeQuery and WindowedRangeQuery The goal is to select through a very large number of rows that’s too large to fetch all at once. Many DBAPIs pre-buffer result sets fully, and otherwise it can be difficult to keep an active cursor when using an option like psycopg2’s server side cursors. The usual alternative, i.e. to page through the results using LIMIT/OFFSET, has the downside that the OFFSET will scan through all the previous rows each time in order to get to the requested row. To overcome this, there are two approaches to page through results without using OFFSET. The simplest is to order the results by a particular unique column (usually primary key), then fetch chunks using LIMIT only, adding a WHERE clause that will ensure we only fetch rows greater than the last one we fetched). This will work for basically any database backend and is illustrated below for MySQL. The potential downside is that the database needs to sort the full set of remaining rows for each chunk, which may inefficient, even though both recipes presented here assume the sort column is indexed. However, the approach is very simple and can likely work for most ordinary use cases for a primary key column on a database that does not support window functions. def windowed_query(q, column, windowsize): \"\"\"\"Break a Query into chunks on a given column.\"\"\" single_entity = q.is_single_entity q = q.add_column(column).order_by(column) last_id = None while True: subq = q if last_id is not None: subq = subq.filter(column \u003e last_id) chunk = subq.limit(windowsize).all() if not chunk: break last_id = chunk[-1][-1] for row in chunk: if single_entity: yield row[0] else: yield row[0:-1] if __name__ == \"__main__\": from sqlalchemy import Column, Integer, create_engine from sqlalchemy.orm import Session from sqlalchemy.ext.declarative import declarative_base import random Base = declarative_base() class Widget(Base): __tablename__ = \"widget\" id = Column(Integer, primary_key=True) data = Column(Integer) e = create_engine(\"mysql://scott:tiger@localhost/test\", echo=\"debug\") Base.metadata.drop_all(e) Base.metadata.create_all(e) # get some random list of unique values data = set([random.randint(1, 1000000) for i in range(10000)]) s = Session(e) s.add_all([Widget(id=i, data=j) for i, j in enumerate(data, 1)]) s.commit() q = s.query(Widget) for widget in windowed_query(q, Widget.data, 1000): print(\"data:\", widget.data) A more elaborate way to do this, which allows that the table rows are fully sorted only once, is to use a window function in order to establish the exact range for each “chunk” ahead of time, and then to yield chunks as rows selected within that range. This works only on databases that support windows functions. This recipe has been on the SQLAlchemy Wiki for a long time but it’s not clear how much advantage it has over the previous simpler approach; both approaches should be evaluated for efficiency for a given use case. import sqlalchemy from sqlalchemy import and_, func def column_windows(session, column, windowsize): \"\"\"Return a series of WHERE clauses against a given column that break it into windows. Result is an iterable of tuples, consisting of ((start, end), whereclause), where (start, end) are the ids. Requires a database that supports window functions, i.e. Postgresql, SQL Server, Oracle. Enhance this yourself ! Add a \"where\" argument so that windows of just a subset of rows can be computed. \"\"\" def int_for_range(start_id, end_id): if end_id: return and_( column\u003e=start_id, column\u003cend_id ) else: return column\u003e=start_id q = session.query( column, func.row_number().\\ over(order_by=column).\\ label('rownum') ).\\ from_self(column) if windowsize \u003e 1: q = q.filter(sqlalchemy.text(\"rownum %% %d=1\" % windowsize)) intervals = [id for id, in q] while intervals: start = intervals.pop(0) if intervals: end = intervals[0] else: end = None yield int_for_range(start, end) def windowed_query(q, column, windowsize): \"\"\"\"Break a Q","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:2","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":null,"content":"做为混迹互联网行业十几年的中年人，曾经搭建好几次的博客以及微信公众号，但实际上并未保持持续写博客的状态，实际上在过往写过一部分文章，都零散的分散在电脑的各个角落里面。 如今再一次用 hugo 以及现成的 LoveIt 主题搭建了一个博客，那么，接下去除了写点新的东西以外，几篇老文章到时候也陆陆续续在这里露露面好了。 ","date":"2022-04-02","objectID":"/first_post/:0:0","tags":null,"title":"01.博客开篇","uri":"/first_post/"}]