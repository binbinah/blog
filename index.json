[{"categories":["生活"],"content":"本文记录一下饭组的端午节下乡出游计划（也就是计划一下如何把大伙儿拐进山里面） ","date":"2022-05-30","objectID":"/a_way_to_home/:0:0","tags":["生活"],"title":"饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"出发前准备 72 小时核酸检测做一下，确保旅游时间内，核算都在有效期内。 自驾汽车状态检查一下，确保路途自驾安全，自驾来回预计消耗半箱油。 照相机📷，打卡必备。 手机充电线以及充电宝。 一套换洗衣物避免意外需要换洗的场景。 防蚊虫喷雾、防晒喷雾、酒精棉片，碘伏等简易应急物品 ","date":"2022-05-30","objectID":"/a_way_to_home/:0:1","tags":["生活"],"title":"饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"概览 时间：2020年6月3日 ～ 2020年6月4日 地点：杭州杭州市 ～ 杭州千岛湖 人数：X8大人（X1人类），X1人类（X8大人） 交通：X8大人：X1万，X1人类：X1万 住宿：X8大人：X1万，X1人类：X1万 ","date":"2022-05-30","objectID":"/a_way_to_home/:0:2","tags":["生活"],"title":"饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"详细行程 day01 从杭州出发，到千岛湖，出发时间：09:00，预期路上耗费时间：2小时30分，预期抵达千岛湖镇时间：11:30。 到达千岛湖镇之前，建议先去千岛湖啤酒博物馆，可以带上一批啤酒，接下来的行程中喝起来。 千岛湖镇落脚点建议在十字路口附近，todo 找个停车场。 午饭选项： 大众点评评分高的。 骑龙巷附近遛遛看看。 推荐： 午间快速压马路打卡地段：骑龙巷 环湖路线从淳杨线开始，也就是顺时针环湖。 沿途景点安排：todo day02 ","date":"2022-05-30","objectID":"/a_way_to_home/:0:3","tags":["生活"],"title":"饭组端午环湖自驾计划","uri":"/a_way_to_home/"},{"categories":["生活"],"content":"老拱墅区：拱宸桥附近、拱北小区附近，以及后来混迹过的西湖区益乐新村、政苑小区都有特别多的回忆。如今已经到了无暇去回顾这些回忆的阶段了。 昨天带着小孩户外活动，但天气不好，下了点小雨，在古翠路公园绕了一圈就打算去原先常常走过的小街道逛逛。西湖区的世纪新城以及嘉绿苑周边的街道，都潜藏这很多的宝藏小店。各种有氛围和年代的大小咖啡店、还有十几年如一日，至今仍然不支持手机点餐的港式茶餐厅等等。 我原本想着一边走一边和幼崽讲述他老爹以前在这条路上吃过的东西，做过的事情。然而走了一段路后才发现，鲜有店面经过时间的洗礼还依旧存活至今。很多之前吃过饭的店面，到现在都已经不见了，取而代之的是另一个承载了其他人回忆的小店。尽管他们看起来也很「宝藏」，但不是我的宝藏小店了。 所以对不同的人来说，所谓的「宝藏」其实是相对的，物件身上承载的情怀第一，价值等其他属性次之。 路过一家蛋糕店，因为临近傍晚了，店里面几乎卖光了今日的蛋糕，但柜台里面还有一盒马卡龙小蛋糕，买了它尝了尝，结果太甜了，喜欢吃糖的儿子也这么说。 回来的路上经过了一家卖各种酒类的小店，我突然想起了8年前曾经在这家店里买过的酒，我们买了很多很多的进口啤酒，运回公司，放在一个装满冰块的汽油桶里面，开始开 party。我喝着酒，开着电脑给客户解答问题。那是一个无限可能的日子里。 这家卖酒的店还在，是这些街道上为数不多的还开着的店。傍晚的灯光亮起来，特别好看。我退后几步，照了张相 但是我已经回忆不起来当时买酒的时候，它是不是这家店，是不是换过名字了？是不是换过老板了，我一无所知。 天色渐渐暗下来，于是带着儿子跨上小红车回家去了，西湖区很多老破小，但是很生活的味道，是一种很老，却很有生命力的味道。 街拍照片已经上传至我的 IG ","date":"2022-04-25","objectID":"/westlake_district/:0:0","tags":["生活"],"title":"05.昨天遛了个街...","uri":"/westlake_district/"},{"categories":["技术支持"],"content":" 本文于 2022年4月15日发表于有赞技术支持公众号 链接：https://mp.weixin.qq.com/s/tMAouzvBzyb-uCsVlMLdsA 在企业服务行业，了解客户的使用场景，倾听来自客户的使用反馈，分析客户的需求，并持续改善产品的使用体验，对产品的销售拓客、客户续费都有着积极的影响。 有一些中小规模的企业服务产品，产品运营团队可能承担了一部分客户的支持和答疑工作，也就是客户的吐槽、反馈能直接抵达产品研发团队，客户的有价值的需求就能快速加入到主线的研发流程中，进一步提升客户的产品使用体验。 但是事情并不是都如此理想化，在一些功能和技术密度更加复杂的企业服务产品中，售后技术支持的角色是不可或缺的。也就是售后技术支持的出现，让很大比例的客户问题在售后技术支持一侧进行了闭环，为产品和研发团队缓解了大量的日常咨询和答疑压力。 然而售后支持的出现也会带来另一个问题，也就是上面说的，客户和产品研发之间出现了一个售后团队，如何让产品研发团队能直观清晰的感知来自客户的重要的需求和吐槽，成了新的需要解决的难题。 在有赞，我们认为一个健康的技术支持，日常的工作精力绝对不能 100% 分布在解决商家的线上问题上。解决线上问题很重要，但是如果只解决线上问题，对团队和对个人都是一种慢性伤害。 因此，有赞技术支持除了解决线上问题，另一个典型的工作内容就是分析商家反馈的线上问题，从自己负责的产品模块中，分析出高频商家问题、可以优化的产品细节，以及评估 BUG 是否潜在升级为故障的风险，将这些内容快速的反馈到产研团队，并推进他们排期迭代。 敏锐的你一定发现上文 「推进他们排期迭代」是一个高度抽象和概括的描述，那么具体要怎么做才能让产研认可你提到优化点，是「迫切、批量、重要」的商家需求和线上问题，而不是一拍脑袋的「野需求」呢？没错，就像软件开发工程师圈子的那句话类似：「Talk is cheap ，show me the code」。在推进产研优化这块，同样「Talk is cheap」，此时我们就需要 「show you the results of data analysis」 为了能收集到数据，有赞技术支持在承接线上问题的工单系统中，分了这几个维度去标记每一个线上问题： 问题归属的产品模块 问题归属类型（有效咨询、技术 BUG、无效问题、产品 BUG） 问题归属的商家分级 每一个技术支持在处理线上问题的过程中，都会对这些问题进行打标分类，以便后续通过数据统计平台进行数据展示。 通过上述三个维度，我们就能分析出： 具体是哪一个产品模块出现的商家咨询量最多。 产品逻辑缺陷、或者技术 BUG 导致的问题有哪些。 重点客户的线上问题的具体情况。 最后在数据分析页面，我们就能方便的统计想要查看的线上问题的趋势、分类以及明细列表的视图。哪些产品模块，哪些重点客户、哪些 BUG问题需要重点优化，就非常的清晰明了。 示例界面： 实际上，有赞的产品细节非常的庞大，至今技术支持还需要通过查阅各类数据分析，去手动去生成一些线上问题双周报、月报等报表数据。我们仍然在致力于通过日常标准化的对每个问题打标的动作，然后自动生成线上问题数据报表。 一份完整的阶段售后支持报告，包含了这些内容： 售后支持统计，包括：数量趋势，各个流转环节的效率等。 软件质量分析，包括：BUG 分类，故障、以及故障预警，BUG 验收质量等。 需求进展分析，包括：商家需求、高频问题、技术干预等 这份全面的报表，可以按需自动生成多个部门的报表，触达各个产研部门。技术支持无需再去各个平台收集数据手动统计报表，统一生成的规范的报表，对技术支持来说也是一个生产力的解放。 我们常说互联网行业创业有很多的赛道，而选好赛道起跑后，大到公司运营，小到部门协作，都需要依赖各种分析数据进行决策，以确定下一步的重点和发展方向。 回到售后支持如何推进商家需求的话题上还是如此，对线上问题进行完善的分类标记，产出客观准确的数据，然后用数据去驱动产品的优化，是最准确、有效且让人信服的方式。 ","date":"2022-04-18","objectID":"/tech_support_wechat_article/:0:0","tags":["技术支持"],"title":"04.用数据分析驱动产品优化","uri":"/tech_support_wechat_article/"},{"categories":["python"],"content":"前段时间购买了@piglei 的《Python 工匠》，现在已经看了 1/3 了，这本书的行文的确是流畅，看起来很舒服，对于 Python 的高阶用法的建议和说明也都非常的不错，我打算开一篇博文单独记录一下，一些自己比较容易遗漏或者忘记的一些知识点。 ","date":"2022-04-05","objectID":"/python-books/:0:0","tags":["python","读书笔记"],"title":"03.关于《Python 工匠》的摘要笔记","uri":"/python-books/"},{"categories":["python"],"content":"近期在使用 SQLAlchemy 读取大批量数据的时候，遇到了一个问题，因为数据量过大而查询进程被 Kill 的问题，就想到了使用生成器或者单个请求拆分多次查询的方法。在 github 上找到了一篇 Wiki，照着 Wiki 中的方式，成功解决了 SQLAlchemy 查大数据失败的问题。 这篇 Wiki 文章比较短小，英文读起来也不吃力，但想着还是顺便练习一下翻译，水一篇博客好了。 ","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:0","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":["python"],"content":"译文： Todo ","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:1","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":["python"],"content":"原文： 原文链接：RangeQuery-and-WindowedRangeQuery： RangeQuery and WindowedRangeQuery The goal is to select through a very large number of rows that’s too large to fetch all at once. Many DBAPIs pre-buffer result sets fully, and otherwise it can be difficult to keep an active cursor when using an option like psycopg2’s server side cursors. The usual alternative, i.e. to page through the results using LIMIT/OFFSET, has the downside that the OFFSET will scan through all the previous rows each time in order to get to the requested row. To overcome this, there are two approaches to page through results without using OFFSET. The simplest is to order the results by a particular unique column (usually primary key), then fetch chunks using LIMIT only, adding a WHERE clause that will ensure we only fetch rows greater than the last one we fetched). This will work for basically any database backend and is illustrated below for MySQL. The potential downside is that the database needs to sort the full set of remaining rows for each chunk, which may inefficient, even though both recipes presented here assume the sort column is indexed. However, the approach is very simple and can likely work for most ordinary use cases for a primary key column on a database that does not support window functions. def windowed_query(q, column, windowsize): \"\"\"\"Break a Query into chunks on a given column.\"\"\" single_entity = q.is_single_entity q = q.add_column(column).order_by(column) last_id = None while True: subq = q if last_id is not None: subq = subq.filter(column \u003e last_id) chunk = subq.limit(windowsize).all() if not chunk: break last_id = chunk[-1][-1] for row in chunk: if single_entity: yield row[0] else: yield row[0:-1] if __name__ == \"__main__\": from sqlalchemy import Column, Integer, create_engine from sqlalchemy.orm import Session from sqlalchemy.ext.declarative import declarative_base import random Base = declarative_base() class Widget(Base): __tablename__ = \"widget\" id = Column(Integer, primary_key=True) data = Column(Integer) e = create_engine(\"mysql://scott:tiger@localhost/test\", echo=\"debug\") Base.metadata.drop_all(e) Base.metadata.create_all(e) # get some random list of unique values data = set([random.randint(1, 1000000) for i in range(10000)]) s = Session(e) s.add_all([Widget(id=i, data=j) for i, j in enumerate(data, 1)]) s.commit() q = s.query(Widget) for widget in windowed_query(q, Widget.data, 1000): print(\"data:\", widget.data) A more elaborate way to do this, which allows that the table rows are fully sorted only once, is to use a window function in order to establish the exact range for each “chunk” ahead of time, and then to yield chunks as rows selected within that range. This works only on databases that support windows functions. This recipe has been on the SQLAlchemy Wiki for a long time but it’s not clear how much advantage it has over the previous simpler approach; both approaches should be evaluated for efficiency for a given use case. import sqlalchemy from sqlalchemy import and_, func def column_windows(session, column, windowsize): \"\"\"Return a series of WHERE clauses against a given column that break it into windows. Result is an iterable of tuples, consisting of ((start, end), whereclause), where (start, end) are the ids. Requires a database that supports window functions, i.e. Postgresql, SQL Server, Oracle. Enhance this yourself ! Add a \"where\" argument so that windows of just a subset of rows can be computed. \"\"\" def int_for_range(start_id, end_id): if end_id: return and_( column\u003e=start_id, column\u003cend_id ) else: return column\u003e=start_id q = session.query( column, func.row_number().\\ over(order_by=column).\\ label('rownum') ).\\ from_self(column) if windowsize \u003e 1: q = q.filter(sqlalchemy.text(\"rownum %%%d=1\" % windowsize)) intervals = [id for id, in q] while intervals: start = intervals.pop(0) if intervals: end = intervals[0] else: end = None yield int_for_range(start, end) def windowed_query(q, column, windowsize): \"\"\"\"Break a Qu","date":"2022-04-02","objectID":"/sqlalchemy-rangequery/:0:2","tags":["python","sqlalchemy"],"title":"02.[译文] RangeQuery and WindowedRangeQuery","uri":"/sqlalchemy-rangequery/"},{"categories":null,"content":"做为混迹互联网行业十几年的中年人，曾经搭建好几次的博客以及微信公众号，但实际上并未保持持续写博客的状态，实际上在过往写过一部分文章，都零散的分散在电脑的各个角落里面。 如今再一次用 hugo 以及现成的 LoveIt 主题搭建了一个博客，那么，接下去除了写点新的东西以外，几篇老文章到时候也陆陆续续在这里露露面好了。 ","date":"2022-04-02","objectID":"/first_post/:0:0","tags":null,"title":"01.博客开篇","uri":"/first_post/"}]